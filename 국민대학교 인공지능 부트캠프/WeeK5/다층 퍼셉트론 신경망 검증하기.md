- 오늘 한 것은 다중퍼셉트론 신경망을 검증하는 것이다.
- dataset에 대한 속성은 아래와 같다.
  - 임신횟수
  - 경구 포도당 내성검사에서 2시간 동안의 혈장 포도당 농도
  - 이완기 혈압(mm Hg)
  - 상두근 피부 두겹 두께(mm)
  - 2시간 혈청 인슐린(mu U/ml)
  - 체질량 지수
  - 당뇨 직계 가족력
  - 나이(세)

- 결과는 0과1이며 이는 5년이내에 당뇨병의 발병여부를 뜻한다.0은 발병안함,1은 발병한다는 것을 의미한다.

#### 시험셋의 샘플 X를 살펴보자
```python
import numpy as np

x_test=np.loadtxt("x_test.csv",delimiter=",")
np.set_printoptions(suppress=True) 
print(x_test)
```
-그럼 실행결과는 아래와 같다.(한 부분만 추출한 것이다.)
`[[  2.    122.     76.     27.    200.     35.9     0.483  26.   ].....`
- 위 값은 8가지의 속성에 대한 value다.

#### 훈련셋을 가시화 시킨다.
```python
import pandas as pd

df=pd.DataFrame(x_train)

df=df.rename(columns={0:"Number of times pregnant",
                     1:"Plasma glucose concentration",
                     2:"Diastolic  blood pressure",
                     3:"Triceps skin fold thickness",
                     4:"2-Hour serum insulin",
                     5:"Body mass index",
                     6:"Diabetes pedigree function",
                     7:"Age"})

histo=df.hist(figsize=[10,10]) #각각 컬럼과 로우의 관계를 히스토그램으로 보여줌
```

#### 훈련셋의 라벨 통계도 구한다.
```python
print((y_train==0).sum())
print((y_train==1).sum())
```

#### 데이터 전처리를 한다.
```python
mean=x_train.mean(axis=0)
x_train-=mean
std=x_train.std(axis=0)
x_train/=std

print(mean)
print(std)
```

#### 입력속성이 8개이고, 출력이 1개인 네트워크 아키텍쳐를 설계하고, 컴파일 한다.
```python
model =Sequential([
      Dense(32,input_dim=8,activation="relu"),
      Dense(16,activation="relu"),
      Dense(1,activation="sigmoid")
])
model.compile(loss="binary_crossentropy",optimizer="rmsprop",metrics=["accuracy"])
```

#### 콜백함수를 이용하여 검증셋의 손실값이 제일 낮은 모델을 저장한다.
```python
checkpoint_callback=ModelCheckpoint("best_model.h5",save_best_only=True,monitor="val_loss")

hist=model.fit(x_train,y_train,validation_split=0.2,epochs=500,batch_size=32,callbacks=[checkpoint_callback])
```
- 실행결과는 아래와 같다(일부분만 추출한 것이다.)
```
Epoch 38/500
18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7929 - val_loss: 0.3984 - val_accuracy: 0.7857
Epoch 39/500
18/18 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.7964 - val_loss: 0.3981 - val_accuracy: 0.7857
Epoch 40/500
18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.7911 - val_loss: 0.3988 - val_accuracy: 0.7857
Epoch 41/500
18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.7964 - val_loss: 0.3990 - val_accuracy: 0.7857
Epoch 42/500
18/18 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.7946 - val_loss: 0.3996 - val_accuracy: 0.7857
```

#### 검증셋,훈련셋에 대한 loss,accuracy를 그래프를 통해서 확인한다.
```python
import matplotlib.pyplot as plt

fig,loss_ax=plt.subplots()

acc_ax=loss_ax.twinx()

loss_ax.plot(hist.history["loss"],"y",label="train loss")
loss_ax.plot(hist.history["val_loss"],"r",label="val loss")

acc_ax.plot(hist.history["accuracy"],"b",label="train acc")
acc_ax.plot(hist.history["val_accuracy"],"g",label="val acc")

loss_ax.set_xlabel("epoch")
loss_ax.set_ylabel("loss")
acc_ax.set_ylabel("accuray")

loss_ax.legend(loc="upper left")
acc_ax.legend(loc="lower left")

plt.show()
```
- Week4에서 한 다중퍼셉트론내용 큰 차이는 없다. 그래서 몇몇 키워드에 대해서는 설명을 생략했다 


